---
title: "Detección de anomalías"
subtitle: "Minería de datos: aprendizaje no supervisado y detección de anomalías"
author: "Francisco Luque Sánchez"
date: "21/12/2019"
titlepage: true
titlepage-background: "background.pdf"
headrule-color: "435488"
urlcolor: 'blue'
script-font-size: \scriptsize
nncode-block-font-size: \scriptsize
output:
    pdf_document:
        number_sections: yes
        template: eisvogel
---

```{r setup, include=F}
knitr::opts_chunk$set(echo = FALSE)
set.seed(0)
library(ggplot2)
library(knitr)
library(rmatio)
library(GGally)
library(gridExtra)

## Cargamos las librerías y funciones pertinentes
source("Outliers_A2_Librerias_a_cargar_en_cada_sesion.R")

source("Outliers_A3_Funciones_a_cargar_en_cada_sesion.R")
```

# Introducción

En este trabajo se va a desarrollar una práctica sobre detección de
ejemplos anómalos en un conjunto de datos. Se define como dato anómalo
aquel elemento de un conjunto de datos cuyo comportamiento difiere del
comportamiento esperable. Este comportamiento se traduce en que los
valores registrados para alguna de las variables se sale de los
valores esperados. En función de la naturaleza de la desviación,
podremos tener distintos tipos de comportamientos anómalos:

- Ejemplos que presentan un valor extremo para alguno de los atributos
medidos.
- Ejemplos que presentan una combinación de valores anormal para
varias columnas estudiadas en conjunto, pero con valores comunes si
son estudiados individualmente.

Estudiaremos distintas técnicas de detección de datos anómalos, tanto
del primer como del segundo tipo.

# IQR

El primer método que estudiaremos está basado en el rango
intercuartílico.  Este método trabaja de forma univariante, tratando
todas las variables del conjunto por separado. Por tanto, nos
permitirá detectar valores extremos en las variables por separado,
pero no nos servirá para detectar combinaciones atípicas de valores.
El funcionamiento del test se basa en el estudio de los cuartiles de
una distribución normal. Cuando se trabaja con variables normalmente
distribuidas, un enfoque típico para la detección de anomalías
consiste en considerar como anómalos aquellos datos que se salen del
intervalo $(\mu - k\sigma, \mu + k\sigma)$, donde $\mu$ y $\sigma$ son
la media y la desviación típica de la distribución,
respectivamente. En función del valor de $k$ que tomemos, cubriremos a
un mayor número de puntos de la distribución normal. En concreto,
suele tomarse el intervalo con $k=2$, de forma que aproximadamente el
95 % de los valores de la distribución caen en el intervalo, o $k=3$,
intervalo en el que se encuentran el 99.7 % de los valores. Los valores
de la distribución que quedan fuera de estos límites se consideran datos
atípicos

No obstante, la asunción de normalidad en los datos es una suposición
fuerte, que usualmente no se cumple. Además la media y la desviación
típica de los datos son dos estadísticos muy sensibles a la existencia
de valores anómalos. De esta forma, en lugar de utilizar el método
descrito anteriormente, resulta más útil comparar el comportamiento
del rango intercuartílico con el de la desviación, y utilizar el
primer estadístico, que es más robusto ante la existencia de valores
atípicos.  Para la distribución normal, el primer cuartil está en el
valor $-0.67$, y el tercer cuartil en el valor $0.67$. El rango
intercuartílico es, por tanto $1.34$, Tomando entonces el valor $k' =
1.5$, tenemos que el intervalo $(-1.5*IQR, 1.5*IQR)$ contiene
aproximadamente los mismos valores que el intervalo $(-2\sigma,
2\sigma)$.

Utilizando esta justificación, el método IQR etiqueta como datos
anómalos normales para una variable aquellos que se desvían de la
media más de 1.5 por el valor del rango intercuartílico. Por un
razonamiento similar, se marcan como datos anómalos extremos aquellos
que se desvían de la media más de 3*IQR.

## Aplicación del algoritmo

Pasamos a aplicar este método para detectar outliers en nuestro
conjunto de datos. Mostraremos en primer lugar el proceso completo
para una variable, y lo aplicaremos después para todas las demás:

```{r, echo=T, fig.height=4}
## Leemos el dataset y seleccionamos una columna
# dataset <- read.csv("dataset/yeast.data")
dataset <- as.data.frame(read.mat("dataset/thyroid.mat")$X)
columna.scaled <- scale(dataset$V5)

## Calculamos los cuartiles y el IQR
cuartil.primero <- quantile(columna.scaled, .25)
cuartil.tercero <- quantile(columna.scaled, .75)
iqr             <- cuartil.tercero - cuartil.primero

## Calculamos los valores a partir de los cuales se consideran los outliers
extremo.superior.outlier.normal <- cuartil.tercero + 1.5*iqr
extremo.inferior.outlier.normal <- cuartil.primero - 1.5*iqr
extremo.superior.outlier.extremo <- cuartil.tercero + 3*iqr
extremo.inferior.outlier.extremo <- cuartil.primero - 3*iqr

## Construimos los vectores que nos determinan los outliers
vector.es.outlier.normal <- (
    (columna.scaled > extremo.superior.outlier.normal &
     columna.scaled < extremo.superior.outlier.extremo) |
    (columna.scaled < extremo.inferior.outlier.normal &
     columna.scaled > extremo.inferior.outlier.extremo)
)

vector.es.outlier.extremo <- (
    columna.scaled < extremo.inferior.outlier.extremo |
    columna.scaled > extremo.superior.outlier.extremo
)

## Calculamos los valores normales y extremos
claves.outliers.normales <- which(vector.es.outlier.normal)
data.frame.outliers.normales <- dataset[claves.outliers.normales,]
valores.outliers.normales <- data.frame.outliers.normales["V5"]

claves.outliers.extremos <- which(vector.es.outlier.extremo)
data.frame.outliers.extremos <- dataset[claves.outliers.extremos,]
valores.outliers.extremos <- data.frame.outliers.extremos['V5']

valores.normalizados.outliers.normales <- columna.scaled[claves.outliers.normales]

par(mfrow=c(1,2))
## Mostramos gráficamente los outliers
MiPlot_Univariate_Outliers(columna.scaled, claves.outliers.normales,
                           "Outliers normales")
MiPlot_Univariate_Outliers(columna.scaled, claves.outliers.extremos,
                           "Outliers extremos")
```

Una vez hemos visto cómo se aplica el método a una determinada columna, nos
interesará aplicarlo a todas las variables de nuestro conjunto (ocultamos
el código porque no aporta nueva información). Mostramos gráficamente los
resultados:

```{r, fig.height=3.4}
## Repetimos la operacieón con una función del fichero A2
indices.de.outliers.en.alguna.columna <- vector_claves_outliers_IQR_en_alguna_columna(dataset)

## Calculamos el número de outliers totales por columna
frame.es.outlier <- sapply(
    1:ncol(dataset), vector_es_outlier_IQR, datos = dataset
)

frame.es.outlier.extremo <- sapply(
    1:ncol(dataset), vector_es_outlier_IQR, datos = dataset, coef = 3
)

frame.es.outlier.normal <- (frame.es.outlier & !frame.es.outlier.extremo)

## Mostramos gráficamente los outliers
normal.outliers <- lapply(1:ncol(dataset), function(x) {
    MiPlot_Univariate_Outliers(dataset[,x],
                               frame.es.outlier.normal[,x],
                               paste("Outliers normales - columna", x))
})
extreme.outliers <- lapply(1:ncol(dataset), function(x) {
    MiPlot_Univariate_Outliers(dataset[,x],
                               frame.es.outlier.extremo[,x],
                               paste("Outliers extremos - columna", x))
})

foo <-sapply(1:ncol(dataset), function(x) grid.arrange(
                                              normal.outliers[[x]],
                                              extreme.outliers[[x]], ncol=2)
             )

numero.total.outliers.por.columna <- apply(frame.es.outlier, 2, sum)

kable(as.data.frame(t(numero.total.outliers.por.columna)),
      col.names = c("Columna 1", "Columna 2", "Columna 3",
                    "Columna 4", "Columna 5", "Columna 6"),
      caption = "Número de outliers en cada columna del conjunto de datos"
      )
```

Se pueden extraer varias conclusiones de las gráficas y la tabla
anteriores. En primer lugar, tenemos que la variable primera no tiene
outliers de ningún tipo, mientras que en el resto de variables se
tiene un número bastante considerable. El conjunto tiene unos 3800
elementos, así que 400 outliers, como llega a tener la variables 2,
suponen más del 10 % de los valores, lo cual es un número anormalmente
alto. Un comportamiento curioso que se puede observar también es la
distribución de los outliers. En todas las variables ocurre que los
outliers se concentran en los valores altos. Esto nos indica que
la distribuciones están fuertemente sesgadas a la derecha. El
caso más extremo lo tenemos para la segunda variable, como podemos
observar a continuación:

```{r}
ggplot(dataset, aes(x=V2)) + geom_histogram(bins=10)
```

Donde tenemos el grueso de los datos agrupado en la parte izquierda
del gráfico (cercanos a 0) y un pequeño grupo de valores dispersos en
la parte derecha. Sería interesante conocer el origen de las
variables, para intentar buscar las causas que producen estas
desviaciones, pero no se nos proporciona dicha información con el
conjunto de datos.

Una vez hemos visto cómo podemos detectar valores anómalos utilizando
el método del rango intercuartílico, vamos a ver cómo podemos dotar
de más robustez a la detección de anomalías univariantes.

# Aplicación de tests estadísticos para la detección de anomalías

En este apartado veremos cómo podemos aplicar tests estadísticos para
la detección de datos anómalos univariantes. En primer lugar,
aplicaremos el test de Grubbs, el cual nos permite saber si existe un
único outlier en una determinada columna del conjunto de datos, y
posteriormente utilizaremos el test de Rosner, el cual nos permitirá
deducir si hay hasta $k$ outliers, para k conocido de antemano.
Comenzamos comentando el test de Grubbs.

## Test de Grubbs

Este test estadístico permite encontrar outliers en una distribución
univariante, asumiendo que existe normalidad en la misma. Existen dos
versiones del test, dependiendo si hacemos el test con una o dos
colas.  La versión del test de una cola nos permite saber si el máximo
o el mínimo de los valores es anómalo, pero no trabaja sobre ambos
valores simultáneamente. Nosotros utilizaremos el test de dos colas,
que trabaja sobre toda la muestra. Para ambas versiones del test, las
hipótesis que plantea el mismo son las siguientes.

- $H_0$: No hay anomalías en el conjunto de datos
- $H_1$: Hay exactamente una anomalía en el conjunto de datos

El estadístico del test de Grubbs se define como:

\[
G = \frac{\max\limits_{i=1,..., N} \lvert Y_i - \bar{Y} \rvert}{S}
\]

Donde $\bar{Y}$ y $S$ representan la media y la desviación típica
muestrales, simultáneamente. Para el test de dos colas, la hipótesis
nula se rechaza para un nivel de significación $\alpha$ si el
estadístico $G$ cumple:

\[ G>{\frac {N-1}{{\sqrt {N}}}}{\sqrt {{\frac {t_{{\alpha
/(2N),N-2}}^{2}}{N-2+t_{{\alpha /(2N),N-2}}^{2}}}}} \]

Donde $t_{{\alpha/(2N),N-2}}$ es el valor crítico para el nivel de
significación $\alpha/2N$ de una distribución T de Student con $N-2$
grados de libertad. Vamos a ver cómo podemos aplicar este test a una
columna de nuestro conjunto de datos.

```{r, echo=T}
selected.col <- dataset$V4

## Dado que el p-valor es inferior a 0.05, tenemos que el valor de mayor
## dispersión respecto de la media es un valor anómalo
grubbs.test(selected.col, two.sided = T)
indice.de.outlier.Grubbs <- order(abs(selected.col - mean(selected.col)),
                                  decreasing = T)[1]
valor.de.outlier.Grubbs <- selected.col[indice.de.outlier.Grubbs]
MiPlot_Univariate_Outliers(selected.col, indice.de.outlier.Grubbs,
                           "Valor outlier según el test de Grubbs")
```

Podemos observar que, para esta variable, se detecta que el valor de
máxima varianza es un valor anómalo. Este test nos permite averiguar,
precisamente, si el valor de máxima varianza se desvía anormalmente
del resto del conjunto de datos. No obstante, ofrece varios problemas.
En primer lugar, sólo nos permite averiguar si hay un valor anómalo,
pero no nos aporta información del resto de puntos. Por ejemplo, en el
caso anterior, el punto que se encuentra cercano al marcado como
outlier, y que presenta el mismo valor de $y$, es claramente otro
punto anómalo. Además de este, probablemente el punto aislado que se
muestra a la derecha también tenga un valor anormalmente alto. Para
estos dos puntos, el test de Grubbs no aporta información. Una posible
forma de solventar esta problemática consiste en ejecutar
iterativamente este algoritmo mientras se sigan encontrando anomalías,
quitando cada vez el punto marcado como anomalía. No obstante, el
hecho de trabajar con un único punto puede producir ciertos
problemas. Por ejemplo existe una problemática conocida como masking,
en la cual la presencia de varios valores anómalos hacen que este
test no permita rechazar la hipótesis nula. Ponemos a continuación
un ejemplo de masking:

```{r}
## Tenemos dos valores claramente anómalos
datos.masking = c(45,56,54,34,32,45,67,45,67,154,125,65)
plot(datos.masking)
grubbs.test(datos.masking, two.sided=T)
```

Obtenemos un p-valor superior a 0.05, por lo que con los niveles de
significación estándar, no podemos rechazar la hipótesis nula y por
tanto no tendríamos ningún outlier. No obstante, podemos observar que
existen dos valores que se desvían significativamente de los valores
normales, pero su presencia hace que la desviación típica del conjunto
de datos aumente, y por tanto este método no detecte su presencia.  En
el siguiente apartado veremos otro text estadístico, que nos permitirá
afrontar esta problemática.

## Test de Rosner

Para solucionar el problema anterior, suelen utilizarse otros tests
estadísticos, que permiten averiguar si hay un número $k$ (fijo de
antemano) de outliers en la muestra. No obstante, estos métodos
carecen de mucho interés, ya que existen tests más informativos, que
nos permiten discernir si existen un número de outliers menor o igual
al número $k$ fijado de antemano, en lugar de necesitar el número
exacto de outliers. Entre estos tests se encuentra el test de Rosner.
Este test trabaja de la siguiente manera. Se calcula la serie de
estadísticos siguiente:

\[
\large R_{i+1} = \frac{|x^{(i)} - \bar x^{(i)}|}{s^{(i)}}
\]

Donde $\bar{x}^{(i)}$ y $\bar{s}^{(i)}$ son la media y la desviación
típica del conjunto tras eliminar los $i$ valores más extremos, y
$x^{(i)}$ es la observación de dicho subconjunto que más se desvía de
la media. Una vez los valores $R_{1}, ..., R_k$ se han calculado, se
realizan una serie de tests de hipótesis consistentes en comparar los
valores $R_i$ con una serie de valores $\lambda_i$, los cuales se
calculan como

\[
\lambda_{i+1} = \frac{t_{p, n-i-2} (n-i-1)}{\sqrt{(n-i-2 + t_{p, n-i-2}) (n-i)}}
\]

Donde de nuevo, $t_{p,n}$ corresponde al percentil $p$ extraído de una
distribución t de Student con $n$ grados de libertad.
